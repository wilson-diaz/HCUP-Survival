{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\tug84786\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lifelines as lf\n",
    "import sklearn as sk\n",
    "import deepsurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>age1</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>race_1.0</th>\n",
       "      <th>race_2.0</th>\n",
       "      <th>race_3.0</th>\n",
       "      <th>race_4.0</th>\n",
       "      <th>race_5.0</th>\n",
       "      <th>race_6.0</th>\n",
       "      <th>race_9.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1076.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1374.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1074.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  event  age1  sex_0.0  sex_1.0  race_1.0  race_2.0  race_3.0  \\\n",
       "0     203.0    1.0  88.0        0        1         0         0         0   \n",
       "1    1076.0    1.0  67.0        1        0         1         0         0   \n",
       "2    1374.0    1.0  87.0        0        1         0         0         0   \n",
       "3    1074.0    1.0  87.0        1        0         1         0         0   \n",
       "4    1980.0    1.0  73.0        0        1         1         0         0   \n",
       "\n",
       "   race_4.0  race_5.0  race_6.0  race_9.0  \n",
       "0         0         0         1         0  \n",
       "1         0         0         0         0  \n",
       "2         1         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_fp = 'clean/afib_425_2_clean.csv'\n",
    "train_df = pd.read_csv(train_dataset_fp)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "# time_col is the header in the df that represents the event time\n",
    "def dataframe_to_deepsurv_ds(df, event_col = 'event', time_col = 'duration'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "# If the headers of the csv change, you can replace the values of \n",
    "# 'event_col' and 'time_col' with the names of the new headers\n",
    "# You can also use this function on your training dataset, validation dataset, and testing dataset\n",
    "train_data = dataframe_to_deepsurv_ds(train_df, event_col = 'event', time_col= 'duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparams = {\n",
    "    'L2_reg': 10.0,\n",
    "    'dropout': 0.4,\n",
    "    'hidden_layers_sizes': [25, 25],\n",
    "    'learning_rate': 1e-05,\n",
    "    'lr_decay': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'n_in': train_data['x'].shape[1],\n",
    "}\n",
    "model = deepsurv.DeepSurv(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training CoxMLP\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaNs detected in inputs, please correct or drop.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7e245a3a71aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# If you have validation data, you can add it as the second parameter to the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdate_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\deepsurv\\deep_surv.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_data, valid_data, n_epochs, validation_frequency, patience, improvement_threshold, patience_increase, verbose, update_fn, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m                 \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                 \u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[0me_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             )\n\u001b[0;32m    588\u001b[0m             \u001b[0mtrain_ci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mci_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\deepsurv\\deep_surv.py\u001b[0m in \u001b[0;36mget_concordance_index\u001b[1;34m(self, x, t, e, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m         return concordance_index(t,\n\u001b[0;32m    470\u001b[0m             \u001b[0mpartial_hazards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             e)\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     def train(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\lifelines\\utils\\concordance.py\u001b[0m in \u001b[0;36mconcordance_index\u001b[1;34m(event_times, predicted_scores, event_observed)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m     54\u001b[0m     event_times, predicted_scores, event_observed = _preprocess_scoring_data(\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mevent_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_observed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     )\n\u001b[0;32m     57\u001b[0m     \u001b[0mnum_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_tied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concordance_summary_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_observed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\lifelines\\utils\\concordance.py\u001b[0m in \u001b[0;36m_preprocess_scoring_data\u001b[1;34m(event_times, predicted_scores, event_observed)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mevent_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_observed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NaNs detected in inputs, please correct or drop.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mevent_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_observed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: NaNs detected in inputs, please correct or drop."
     ]
    }
   ],
   "source": [
    "# DeepSurv can now leverage TensorBoard to monitor training and validation\n",
    "# This section of code is optional. If you don't want to use the tensorboard logger\n",
    "# Uncomment the below line, and comment out the other three lines: \n",
    "# logger = None\n",
    "\n",
    "\n",
    "\n",
    "# Now we train the model\n",
    "update_fn=lasagne.updates.nesterov_momentum # The type of optimizer to use. \\\n",
    "                                            # Check out http://lasagne.readthedocs.io/en/latest/modules/updates.html \\\n",
    "                                            # for other optimizers to use\n",
    "n_epochs = 2000\n",
    "\n",
    "# If you have validation data, you can add it as the second parameter to the function\n",
    "metrics = model.train(train_data, n_epochs=n_epochs, update_fn=update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final metrics\n",
    "print('Train C-Index:', metrics['c-index'][-1])\n",
    "# print('Valid C-Index: ',metrics['valid_c-index'][-1])\n",
    "\n",
    "# Plot the training / validation curves\n",
    "viz.plot_log(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
